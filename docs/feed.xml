<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://jacobfv.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://jacobfv.github.io/" rel="alternate" type="text/html" /><updated>2022-02-27T09:45:02-06:00</updated><id>https://jacobfv.github.io/feed.xml</id><title type="html">Jacob Valdez</title><subtitle>Personal portfolio site
</subtitle><entry><title type="html">Ergonomic Optimization</title><link href="https://jacobfv.github.io/blog/ergonomic-optimization/" rel="alternate" type="text/html" title="Ergonomic Optimization" /><published>2021-12-31T00:00:00-06:00</published><updated>2021-12-31T00:00:00-06:00</updated><id>https://jacobfv.github.io/blog/ergonomic-optimization</id><content type="html" xml:base="https://jacobfv.github.io/blog/ergonomic-optimization/">&lt;h2 id=&quot;the-problem&quot;&gt;The Problem&lt;/h2&gt;

&lt;p&gt;I don’t find it easy to remain productive when I’m working at the computer (not to suggest that I am generally productive anyway). I’ve unintentionally conditioned myself that whenever I sit down at the computer, I need to browse the latest papers / popular repositories / system settings / etc. but not actually do the work I came to do. I’m thankful that I’m not overwhelmed with things to do anyway, but I think I could be much more productive than I currently am.&lt;/p&gt;

&lt;h2 id=&quot;what-i-tried&quot;&gt;What I tried&lt;/h2&gt;

&lt;p&gt;I started by recognizing that I needed to change some of my personality traits, routines, and motivations. I started spending more time alone thinking out loud about the things I need to do. This evolved into a journal where I record my thoughts on problems, emotions, and ideas and then reflect on them later. I started using these habits and techniques to think explicitly about how I can continue changing my personality. I made a “Habits” document where I record habits I need to create, stop, and specific techniques that help me change.&lt;/p&gt;

&lt;div class=&quot;row justify-content-sm-center&quot;&gt;
    &lt;div class=&quot;col-sm-6 mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/Journal-12.png&quot; alt=&quot;&quot; title=&quot;planning the next months&quot; /&gt;
    &lt;/div&gt;
    &lt;div class=&quot;col-sm-6 mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/Journal-22.png&quot; alt=&quot;&quot; title=&quot;reviewing what I learned&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The latest extension to my externalized cognitive toolkit is a “Tasks” document. I divide tasks into four categories:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Game plan: scheduled tasks with details&lt;/li&gt;
  &lt;li&gt;Long range: goals to keep focused on in the long range&lt;/li&gt;
  &lt;li&gt;Unscheduled: tasks that are not scheduled yet but should be handled&lt;/li&gt;
  &lt;li&gt;Optional: I don’t want to forget these task entirely, but nothing bad happens if I don’t do them&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If I don’t finish everything on the plate for today, I simply move it over to the next day and work on that at the first chance. However, I generally work to be realistic – but not too conservative – with my demands.&lt;/p&gt;

&lt;div class=&quot;row justify-content-sm-center&quot;&gt;
    &lt;div class=&quot;col-sm-6 mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/Tasks-1.png&quot; alt=&quot;&quot; title=&quot;My task list&quot; /&gt;
    &lt;/div&gt;
    &lt;div class=&quot;col-sm-6 mt-3 mt-md-0&quot;&gt;
        &lt;img class=&quot;img-fluid rounded z-depth-1&quot; src=&quot;/assets/img/Routines-2.png&quot; alt=&quot;&quot; title=&quot;Routines I need to kill&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;outcomes&quot;&gt;Outcomes&lt;/h2&gt;

&lt;p&gt;30 days into this routine, I definitely see positive results. Making a habit of thinking about the things I need to do has helped me to be more productive while avoiding the need to constantly worry ‘did I do this or that?’. Anytime a to do pops in my head, all I have to do is write it down and then I can free my brain to focus on the context I’m currently in.&lt;/p&gt;

&lt;p&gt;Taking time to think out loud and using a gratitude journal has seriously helped me increase control over my emotions which in turn has helped me to be more productive. Journaling has helped me to be more aware of my emotions and to ask myself questions like “what do I feel like doing?” vs. “what should I be doing?”. I really feel like this has helped me be more in control of my decisions.&lt;/p&gt;

&lt;p&gt;Writing my thoughts down and revisiting them later helps me think about them more objectively. I see that I forget so easy without a written memory aid. Things that stressed me out never really mattered anyway. Many of the things that I thought were impossible to do now appear easy or otherwise more manageable. It seems that I have a lot more control of my life than I thought I did. I understand better why people say, “life is like a box of chocolates”; it’s full of color, emotions, thoughts, activities, accomplishments, and surprises. YouTube doesn’t compare to a productive day!&lt;/p&gt;

&lt;h2 id=&quot;going-forward&quot;&gt;Going forward&lt;/h2&gt;

&lt;p&gt;A few days ago, I read through all these cognitive tools, and I was amazed at how they have improved my productivity. Obviously, I’m going to continue using them. However, I don’t want to stop here. Like a manufacturing toolchain that continually gets upgraded, I will continue refining my productivity habits and techniques and I will also start making regular reviews of my journal to avoid repeating any mistakes I’ve made. I may even start a “Mistakes” document to record specific cases to watch out for. I will also start quantifying objectives and subjectives like tasks completed per day, tasks completed / tasks attempted per day, relative emotion positivity and negativity, big breakthroughs per week, etc.&lt;/p&gt;

&lt;p&gt;I’m definitely not perfect, but I’m going to use every tool I have to optimize my habits, personality, productivity, and self. I hope sharing this reflection will help others on their personal journey as well.&lt;/p&gt;</content><author><name></name></author><category term="experiment" /><category term="reflection" /><summary type="html">The Problem</summary></entry><entry><title type="html">Design Patterns for AI</title><link href="https://jacobfv.github.io/blog/design-patterns-for-ai/" rel="alternate" type="text/html" title="Design Patterns for AI" /><published>2021-12-06T00:00:00-06:00</published><updated>2021-12-06T00:00:00-06:00</updated><id>https://jacobfv.github.io/blog/design-patterns-for-ai</id><content type="html" xml:base="https://jacobfv.github.io/blog/design-patterns-for-ai/">&lt;p&gt;Engineering generally starts off with a few high-level abstract ambitions that are refined and translated with increasing clarity into physical realizations. In software engineering, the outputs of this process are unambiguous executable statements. Of course, the whole process is iterative with loops of increasing frequency over the project lifespan and tools automating this optimization (compiler chains, code optimization, high-level languages) operating at progressively higher-levels further reducing the idea to implementation transit time. When neural networks are the focus of software engineering, translation from informal to unambiguous specification is almost immediate (given sufficient understanding of programming, math, deep learning, and thermodynamics) and the brunt of effort shifts (as it rightly should) to actually testing deep learning hypotheses. In the problem space of ‘human-level’ or ‘general’ intelligence, this demands attempting to consolidate as many ideas in neuroscience, cognitive psychology, and artificial intelligence as possible into a working system implementation. While this consolidation appears deceptively simple in literature, the constituent ideas are often lost in implementation&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Therefore, I explicitly list several &lt;strong&gt;unverified hypotheses&lt;/strong&gt; below to help explicitly keep in mind desired cognitive dynamics of increasingly general intelligence.&lt;/p&gt;

&lt;p&gt;TODO: list all my ideas here. citations are allowed, but focus on getting ideas out.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Definite (e.g.: boolean) logic is inconsistent. Thermodynamics governs the mind; not logic. Logical thought only emerges as a dissipating low-entropy trajectory.&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Differentiation evolves representations from vague to crisp culminating in perceptions and actions. Actions (thought words, decisions, motor activity) may modify the world state and destroy their causal crisp representation thus restarting the process.&lt;sup id=&quot;fnref:2:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Synthesis integrates bottom up signals into composite models. Layer units activate if both a top-down model predicts their activation and a bottom-up signal initiates it. Top-down models compete to ‘explain’ a signal and sharpen their precision (cognitive niche) when correctly explained. They gradually loosen their precision if they cannot explain a bottom up signal field. If no sharp models explain a bottom up signal, then imprecise general models become competitive. I think model-signal similarity should be measured by $KL[p_{bu}&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;\tau_{td}]$ which heavily taxes precise models that get selected when they predict low probabilities but true signals have high probabilities. Only the winning model gets optimized by the signal. Loosing models increase their variances.&lt;sup id=&quot;fnref:2:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Heterachical competition requires computing ‘explanatum’ (the model’s predictive accuracy for an input signal normalized over all higher nodes offering predictions) for each unit-model connection. Since explanatum is softmaxed, it may be rolling-averaged as a nice coefficient $a \in [0, 1)$ to inform model optimization and growth.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Real neurons don’t reproduce (they’re simply in abundance and specialize), but the architecture I am describing should only be as complex as necessary. Therefore, models (units with efferent td connections) should binary fizz when their explanatum score $a$ is high. Children can share identical parameters and connectivity since random noise should quickly break their symmetry.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The Gaussian may only represent a small amount of data distributions, but deviations from an estimated and actual distribution are always Gaussian. Also variances. I’m not sure about higher-order moments.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dynamic precision training: start training at 32bit, shrink to 1bit for most pre-training, fine-tune back at 32bit. With 1bit networks at criticality, the network gets the maximum computational power out of its physical substrate, and critical dynamics should translate these gains into learnable logical flexibility. Maybe just stay at 1bit.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If using 1bit representations, maybe have each unit transmit a vector at a time.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Biological synaptic distribution is exponentially bimodal. I should recognize this by federating the weights into a few large neurons and many small connectivity neurons. This may reduce to sparse scattered (global connectivity) and fixed conv (local connectivity) layers.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sparse connectivity is essential, but some local dense connectivity may complement it.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Maybe initialize the network with subgraphs taken from liquid state machines or from connectome research.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Look beyond the computational realization of memory-compute. Maybe neurons exist in a geometric-structured field instead of being entries in an euclidean structured tensor? This allows for dynamically moving neurons, adding neurons, and deleting neurons.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Look beyond statics to focus on system dynamics. Forget feedforward solutions.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Integration – which is not directly solvable like differentiation – represents tremendous complexity reduction. Try to integrate this behavior into the system dynamics perhaps with a differentiable form of Risch’s algorithm or taking advantage of Fourier or Laplace transforms (with inverses)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Use the log-form of geometric mean to allow networks to selectively multiply or add incoming weights.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Regularize synchronization and low entropy into the dynamics to favor system-II-type distributed trajectory emergence. Is their a way to estimate entropy empirically? For known distributions, yes (eg.: assume signals represent actual-expected input. THen they are normal with known confidence intervals.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Design the system to generate minimal activity at each realization level: minimal distributed trajectories, minimal activations, minimal structural connections.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Prediction and reward maximization may supply the bulk of training information. However include maybe 10% data from more structured forms like task-specific probes and decoders as well as intrinsic behavioral objective satisfaction.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;To take advantage of existing pretrained models, other architectures, and for research and development convenience, make the above SOMPNet layer able to interface with other SOMPNet layers, DL layers in general, and python functions in a pythonic interface as if they were directly expressed in math.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At the implementation-end, machine learning research has acquired a diverse array of tools and techniques which represent orders-of-magnitude learning efficiency gains over independent effort. Ever striving to maximize the efficiency with which meaningful information can be infused into a system recommends riding on the energy-momentum of hundreds of thousands of researchers (and zillions of servers). I.E.: incorporating permutations of as many ML research outcomes as possible: codebases, pretrained models, individual weights, architectures, training paradigms, existing datasets, and environments all guided by machine and human intuition. Here are some notable ones:&lt;/p&gt;

&lt;p&gt;TODO: list everything I plan to use here&lt;/p&gt;

&lt;p&gt;-&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;I know all the cuts to make before I enter the shop, but sawing for 2 hours leaves me exhausted and I end up incorrectly measuring or cutting material unless things are marked correctly. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://link.springer.com/book/10.1007/978-3-540-73267-9&quot;&gt;“Neurodynamics of Cognition and Consciousness”&lt;/a&gt; ch.1, 5 &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:2:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; &lt;a href=&quot;#fnref:2:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="reflection" /><category term="ideas" /><category term="agi" /><summary type="html">Engineering generally starts off with a few high-level abstract ambitions that are refined and translated with increasing clarity into physical realizations. In software engineering, the outputs of this process are unambiguous executable statements. Of course, the whole process is iterative with loops of increasing frequency over the project lifespan and tools automating this optimization (compiler chains, code optimization, high-level languages) operating at progressively higher-levels further reducing the idea to implementation transit time. When neural networks are the focus of software engineering, translation from informal to unambiguous specification is almost immediate (given sufficient understanding of programming, math, deep learning, and thermodynamics) and the brunt of effort shifts (as it rightly should) to actually testing deep learning hypotheses. In the problem space of ‘human-level’ or ‘general’ intelligence, this demands attempting to consolidate as many ideas in neuroscience, cognitive psychology, and artificial intelligence as possible into a working system implementation. While this consolidation appears deceptively simple in literature, the constituent ideas are often lost in implementation1. Therefore, I explicitly list several unverified hypotheses below to help explicitly keep in mind desired cognitive dynamics of increasingly general intelligence. I know all the cuts to make before I enter the shop, but sawing for 2 hours leaves me exhausted and I end up incorrectly measuring or cutting material unless things are marked correctly. &amp;#8617;</summary></entry><entry><title type="html">Notes on Neuroscience and AI</title><link href="https://jacobfv.github.io/blog/notes-on-neuroscience-and-ai/" rel="alternate" type="text/html" title="Notes on Neuroscience and AI" /><published>2021-12-03T00:00:00-06:00</published><updated>2021-12-03T00:00:00-06:00</updated><id>https://jacobfv.github.io/blog/notes-on-neuroscience-and-ai</id><content type="html" xml:base="https://jacobfv.github.io/blog/notes-on-neuroscience-and-ai/">&lt;p&gt;&lt;a href=&quot;https://link.springer.com/book/10.1007/978-3-540-73267-9&quot;&gt;“Neurodynamics of Cognition and Consciousness”&lt;/a&gt; preface:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The main theme os this volume is the dynamics of higher cognitive functions. The authors of this volume provide a line of arguments explaining why dynamics plays [a] central role in intelligence in biological brains and in man made artifacts[.] Researcher too often make the mistake of identifying intelligence with the projection of intelligence into a brilliant symbolic form, whereas intelligence is the unity of the path (or dynamic trajectory) leading to the observed formalisms and the intermitted appearance of the formalism itself. Intelligence can be understood only in the context of the complementary nature as it is describes by Kelso and collaborators. Neurodynamics had a peculiar property described as the “edge of stability” or “metastability.” Accordingly, the brain as a complete dynamic system is in perpetual movement from one state to another. When the brain reaches a dominant state, it does not [rest] there, rather it immediately moves on and decays into an unordered state, only to emerge a moment later to another prominent state. Freeman has identified neurophysiologic correlates of this metastable wandering along the landscape of brain dynamics in terms of spatio-temporal patterns of oscillations, sudden jumps or phase transitions of local field potentials.
This book explores various aspects of the neurodynamics of metastable cognitive states. It covers a wide range of research areas relates to dynamics of cognition including experimental studies, dynamical modeling and interpretation of cognitive experiments, and theoretical approaches. Spatio-temporal structures of neural activity and synchronization are manifested as propagating phase cones or phase boundaries over the cortex. Methods to detect, identify and characterize such transient structures are described. Identification fo transients is a very hard pattern recognition problem as the simultaneous overlapping dynamical processes provide a noisy and cluttered domain Advanced techniques of dynamical logic progress from vague concepts to increasingly crisp and articulate forms, which is a promising approach to detect the required complex spatio-temporal correlates of cognitive functions. SIgnificant part of the volume is devotes to the description of various components of the actin-perception cycles and sensory processing domains, from cellular to system levels, and applications in intelligence designs&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2105.07284.pdf&quot;&gt;A brain basis of dynamical intelligence for AI and computational neuroscience&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;To motivate a brain basis of neural computation, we present a &lt;strong&gt;dynamical view of intelligence&lt;/strong&gt; from which we elaborate concepts of sparsity in network structure, temporal dynamics, and interactive learning. In particular, we suggest that temporal dynamics, as expressed through &lt;strong&gt;neural synchrony&lt;/strong&gt;, &lt;strong&gt;nested oscillations&lt;/strong&gt;, and &lt;strong&gt;flexible sequences&lt;/strong&gt;, provide a rich computational layer for reading and updating hierarchical models distributed in long-term memory networks. &lt;em&gt;(p. 1)&lt;/em&gt;
While it is difficult to answer “What is intelligence?”, it is almost as useful to answer “What is intelligence for?”: Intelligence is for adaptive behavior. Otherwise, an organism would have been better off (as in the neuromythology surrounding the sea squirt) ingesting its brain and attaching itself to a rock. &lt;strong&gt;A corresponding yardstick for intelligence would be the degree to which an organism or agent controls its environment in service of continued survival&lt;/strong&gt;. Indeed, &lt;strong&gt;extending this assessment to novel or unpredicted situations, along ecological dimensions, should correlate with generalized problem-solving capacity&lt;/strong&gt;. &lt;em&gt;(p. 2)&lt;/em&gt;
This not-unusual definition of intelligence puts AI (based on disembodied and nonagentic neural nets trained on datasets lacking spatial, temporal, epistemic, mnemonic, social, and/or environmental context) at a disadvantage for purposes beyond hypercompetent regression and classification. Behavior is variable and complex, but it is also hierarchically organized through time in all animals, with &lt;strong&gt;humans exhibiting perhaps the deepest such hierarchies&lt;/strong&gt;. Conceptual knowledge is similarly hierarchical and demanding of flexibility, reconfigurability, and combinatoric expressiveness (cf. the compositionality and systematicity of language). High level cognition is ordered, temporal, and dynamical in that &lt;strong&gt;what came before conditions the &lt;em&gt;meaning&lt;/em&gt; of what comes after, with lifelong horizons in both directions&lt;/strong&gt; &lt;em&gt;(p. 2)&lt;/em&gt;
Typically &amp;lt;1–2% of possible unit-wise connections exist within the cortico-limbic circuits of the hippocampus and neocortex. The impressive combinatorics inherent in this level of sparsity give rise to the intuitive, but perhaps wishful, notion that discovering the underlying motifs, generating functions, or connectomes of synaptic connectivity will unlock the brain’s neural coding secrets. Without such sparsity, dense connectivity either reliably relaxes into pattern completion for recurrent models viz. Hopfield nets, or universal function approximation for feedforward models viz. multi-layer perceptrons and deep learning. &lt;strong&gt;Brains appear to do both, but also much more.&lt;/strong&gt; Density, as in typical artificial neural nets (ANNs), collapses the space of possible network configurations to that of size and layer architecture. Having far fewer degrees-of-freedom greatly restricts structural, and thus functional, diversity. &lt;em&gt;(p. 4)&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;http://www.incompleteideas.net/IncIdeas/BitterLesson.html&quot;&gt;The Bitter Lesson&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This is a big lesson. As a field, we still have not thoroughly learned it, as we are continuing to make the same kind of mistakes. To see this, and to effectively resist it, we have to understand the appeal of these mistakes. We have to learn the bitter lesson that building in how we think we think does not work in the long run. The bitter lesson is based on the historical observations that 1) AI researchers have often tried to build knowledge into their agents, 2) this always helps in the short term, and is personally satisfying to the researcher, but 3) in the long run it plateaus and even inhibits further progress, and 4) breakthrough progress eventually arrives by an opposing approach based on scaling computation by search and learning. The eventual success is tinged with bitterness, and often incompletely digested, because it is success over a favored, human-centric approach.
[…]
The second general point to be learned from the bitter lesson is that the actual contents of minds are tremendously, irredeemably complex; we should stop trying to find simple ways to think about the contents of minds, such as simple ways to think about space, objects, multiple agents, or symmetries. All these are part of the arbitrary, intrinsically-complex, outside world. They are not what should be built in, as their complexity is endless; instead we should build in only the meta-methods that can find and capture this arbitrary complexity. Essential to these methods is that they can find good approximations, but the search for them should be by our methods, not by us. We want AI agents that can discover like we can, not which contain what we have discovered. Building in our discoveries only makes it harder to see how the discovering process can be done.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://proceedings.neurips.cc/paper/2020/file/46a4378f835dc8040c8057beb6a2da52-Paper.pdf&quot;&gt;Pruning neural networks without any data by iteratively conserving synaptic flow&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Recent works have identified, through an expensive sequence of training and pruning cycles, the existence of winning lottery tickets or sparse trainable subnetworks at initialization. This raises a foundational question: can we identify highly sparse trainable subnetworks at initialization, without ever training, or indeed without ever looking at the data? We provide an affirmative answer to this question through theory driven algorithm design&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://research.fb.com/wp-content/uploads/2021/11/Parameter-Prediction-for-Unseen-Deep-Architectures.pdf&quot;&gt;Parameter Prediction for Unseen Deep Architectures&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;By leveraging advances in graph neural networks, we propose a hypernetwork that can predict performant parameters in a single forward pass taking a fraction of a second, even on a CPU. The proposed model achieves surprisingly good performance on unseen and diverse networks. For example, it is able to predict all 24 million parameters of a ResNet-50 achieving a 60% accuracy on CIFAR-10. On ImageNet, top-5 accuracy of some of our networks
approaches 50%. Our task along with the model and results can potentially lead to a new, more computationally efficient paradigm of training networks. Our model also learns a strong representation of neural architectures enabling their analysis.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><category term="notes" /><category term="brain" /><summary type="html">“Neurodynamics of Cognition and Consciousness” preface:</summary></entry><entry><title type="html">Naive Bayes Classifier</title><link href="https://jacobfv.github.io/blog/naive-bayes-classifier/" rel="alternate" type="text/html" title="Naive Bayes Classifier" /><published>2021-11-30T00:00:00-06:00</published><updated>2021-11-30T00:00:00-06:00</updated><id>https://jacobfv.github.io/blog/naive-bayes-classifier</id><content type="html" xml:base="https://jacobfv.github.io/blog/naive-bayes-classifier/">&lt;div class=&quot;jupyter-notebook&quot; style=&quot;position: relative; width: 100%; margin: 0 auto;&quot;&gt;
  &lt;div class=&quot;jupyter-notebook-iframe-container&quot;&gt;
    &lt;iframe src=&quot;../../notebooks/naive_bayes.ipynb.html&quot; style=&quot;position: absolute; top: 0; left: 0; border-style: none;&quot; width=&quot;100%&quot; height=&quot;100%&quot; onload=&quot;this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + &apos;px&apos;&quot;&gt;&lt;/iframe&gt;
  &lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="tutorial" /><category term="jupyter notebook" /><summary type="html"></summary></entry><entry><title type="html">Regularization</title><link href="https://jacobfv.github.io/blog/regularization/" rel="alternate" type="text/html" title="Regularization" /><published>2021-11-11T00:00:00-06:00</published><updated>2021-11-11T00:00:00-06:00</updated><id>https://jacobfv.github.io/blog/regularization</id><content type="html" xml:base="https://jacobfv.github.io/blog/regularization/">&lt;div class=&quot;jupyter-notebook&quot; style=&quot;position: relative; width: 100%; margin: 0 auto;&quot;&gt;
  &lt;div class=&quot;jupyter-notebook-iframe-container&quot;&gt;
    &lt;iframe src=&quot;../../notebooks/linear_regression.ipynb.html&quot; style=&quot;position: absolute; top: 0; left: 0; border-style: none;&quot; width=&quot;100%&quot; height=&quot;100%&quot; onload=&quot;this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + &apos;px&apos;&quot;&gt;&lt;/iframe&gt;
  &lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="tutorial" /><category term="jupyter notebook" /><summary type="html"></summary></entry><entry><title type="html">Estimating the Critical Mass</title><link href="https://jacobfv.github.io/blog/estimating-the-critical-mass/" rel="alternate" type="text/html" title="Estimating the Critical Mass" /><published>2021-11-06T00:00:00-05:00</published><updated>2021-11-06T00:00:00-05:00</updated><id>https://jacobfv.github.io/blog/estimating-the-critical-mass</id><content type="html" xml:base="https://jacobfv.github.io/blog/estimating-the-critical-mass/">&lt;p&gt;I’m sure somebody has made these kinds of analyses in much greater detail, but I wanted to get a sense of the computational limits that we are presently at. Caution: Many of the following numbers are pulled out of the internet &lt;em&gt;without serious effort&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;energy-efficiency&quot;&gt;Energy efficiency&lt;/h2&gt;

&lt;p&gt;At its developed peak, the brain &lt;em&gt;might&lt;/em&gt; have 200 trillion synapses and consume 1760 kJ/day. Making this a ratio, we get 200 trillion synapses / 20W = 10 trillion synapses / watt. Suppose 1 synapse performs at least 10 ‘operations’ per second. Then the brain performs at least 100 TFLOPS with an ideal efficiency exceeding 100 TFLOPS/watt. Compare this to machine computation:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1911.11313.pdf&quot;&gt;This paper (fig 5)&lt;/a&gt; says that in 2020, GPUs reach 100 GFLOPS/watt. However it notes that energy efficiency is exponentially increasing (rough estimate, 10x every 10 years)&lt;/li&gt;
  &lt;li&gt;The v3-32 TPU Pod delivers ~1680 TFLOPS (see below) with &lt;a href=&quot;https://www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/&quot;&gt;estimated power consumption&lt;/a&gt; 200W/core*32cores = 6.4kW. This makes about 250GFLOPS/watt. Only about 3 orders of magnitude less than this brain estimate.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;compute-cost-efficiency&quot;&gt;Compute cost efficiency&lt;/h2&gt;

&lt;p&gt;Suppose it costs $10/day to sustain a human brain. Using the above measures, then the brain can perform at least 2000 trillion operations per second using only $0.0001… for a single second. This makes 17280000 TFLOP/$ or 17 exaflops per dollar. The v3-32 TPU Pod ideally approaches 4 times the single 8 core TPU performance = 4 * 420TFLOPS = 1680TFLOPS at a price $10,512 / month or $0.00400219298 per second. This makes 1680TFLOP/$0.00400219298 or 419769 operations per dollar or about 0.5MFLOP/$. Digital compute infrastructure looks on the order of 10^18 times less cost-efficient than the brain’s biological computation.&lt;/p&gt;

&lt;h2 id=&quot;raw-compute&quot;&gt;Raw Compute&lt;/h2&gt;

&lt;p&gt;The 100 TFLOPS brain estimate looks rather small. This number is easily surpassed by a single TPU pod in terms of brute computational speed – but definitely not efficiency. Still, the TPU pod is not unaffordably expensive. Maybe this infrastructure is sufficient for developing human-level AI!&lt;/p&gt;</content><author><name></name></author><category term="reflection" /><category term="agi" /><category term="brain" /><summary type="html">I’m sure somebody has made these kinds of analyses in much greater detail, but I wanted to get a sense of the computational limits that we are presently at. Caution: Many of the following numbers are pulled out of the internet without serious effort.</summary></entry><entry><title type="html">Image Classification</title><link href="https://jacobfv.github.io/blog/image-classification/" rel="alternate" type="text/html" title="Image Classification" /><published>2021-11-02T00:00:00-05:00</published><updated>2021-11-02T00:00:00-05:00</updated><id>https://jacobfv.github.io/blog/image-classification</id><content type="html" xml:base="https://jacobfv.github.io/blog/image-classification/">&lt;div class=&quot;jupyter-notebook&quot; style=&quot;position: relative; width: 100%; margin: 0 auto;&quot;&gt;
  &lt;div class=&quot;jupyter-notebook-iframe-container&quot;&gt;
    &lt;iframe src=&quot;../../notebooks/image_classification.ipynb.html&quot; style=&quot;position: absolute; top: 0; left: 0; border-style: none;&quot; width=&quot;100%&quot; height=&quot;100%&quot; onload=&quot;this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + &apos;px&apos;&quot;&gt;&lt;/iframe&gt;
  &lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="tutorial" /><category term="jupyter notebook" /><summary type="html"></summary></entry><entry><title type="html">Generalization – Fast and Slow</title><link href="https://jacobfv.github.io/blog/generalization-fast-and-slow/" rel="alternate" type="text/html" title="Generalization – Fast and Slow" /><published>2021-10-31T00:00:00-05:00</published><updated>2021-10-31T00:00:00-05:00</updated><id>https://jacobfv.github.io/blog/generalization-fast-and-slow</id><content type="html" xml:base="https://jacobfv.github.io/blog/generalization-fast-and-slow/">&lt;p&gt;I don’t think I ever fleshed out this idea. I was trying to point out the continual nature of ML optimization.&lt;/p&gt;

&lt;div class=&quot;jupyter-notebook&quot; style=&quot;position: relative; width: 100%; margin: 0 auto;&quot;&gt;
  &lt;div class=&quot;jupyter-notebook-iframe-container&quot;&gt;
    &lt;iframe src=&quot;2021-10-31-generalization-fast-and-slow.ipynb.html&quot; style=&quot;position: absolute; top: 0; left: 0; border-style: none;&quot; width=&quot;100%&quot; height=&quot;100%&quot; onload=&quot;this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + &apos;px&apos;&quot;&gt;&lt;/iframe&gt;
  &lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><category term="ideas" /><category term="jupyter notebook" /><summary type="html">I don’t think I ever fleshed out this idea. I was trying to point out the continual nature of ML optimization.</summary></entry><entry><title type="html">Computatrum</title><link href="https://jacobfv.github.io/blog/computatrum/" rel="alternate" type="text/html" title="Computatrum" /><published>2021-10-19T00:00:00-05:00</published><updated>2021-10-19T00:00:00-05:00</updated><id>https://jacobfv.github.io/blog/computatrum</id><content type="html" xml:base="https://jacobfv.github.io/blog/computatrum/">&lt;meta http-equiv=&quot;refresh&quot; content=&quot;0; URL=/projects/computatrum/&quot; /&gt;</content><author><name></name></author><category term="computatrum" /><category term="code" /><category term="ideas" /><category term="agi" /><summary type="html"></summary></entry><entry><title type="html">Multi-Environment Learning</title><link href="https://jacobfv.github.io/blog/multi-environment-learning/" rel="alternate" type="text/html" title="Multi-Environment Learning" /><published>2021-10-18T00:00:00-05:00</published><updated>2021-10-18T00:00:00-05:00</updated><id>https://jacobfv.github.io/blog/multi-environment-learning</id><content type="html" xml:base="https://jacobfv.github.io/blog/multi-environment-learning/">&lt;p&gt;Multi-environment learning extends the single environment RL paradigm to multiple environments. It’s like multiagent learning – except your only controlling one agent in multiple environments. In this paradigm, the policy $\pi : o_1, o_2, \dots \rightarrow a_1, a_2, \dots$ takes an observation $o_1, o_2, \dots$ from different environments and produces actions $a_1, a_2, \dots$ for all of them simultaneously on each step. You might have a collection loop like:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;observations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;envs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;policy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;observations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;envs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;: At first I couldn’t see why anyone would even want to use this paradigm. After all, if your environments are disjoint, learning to stack blocks probabbly won’t make much a difference on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CartPole&lt;/code&gt;. It’s especially unnecesary to observe both environments simultaneously. However, when your problem domain is in the open-ended world, it is helpful to learn intrinsic priors of logic, social skills, or commonsense knowledge from a simpler area and then apply that information to a more complex environment &lt;em&gt;in context&lt;/em&gt;. When we train our policies in sequential cirricula, the information has to flow from the environment to the weights before it can be used in a later environment. With the multi-environment approach however, policies can learn to access information at the exact time needed by a policy. For instance, you could train an agent where one environment is an interactive ImageNet search engine with no reward and the other environment is a classification challenge with delayed decisions allowed (but still regularized to encourage fast response). Giving the policy the ability to pause and search related images would make it more human like and ideally more accurate. I’m sure you can imagine other scenerios where the multi-environment paradigm is beneficial. (Just consider the computational beenfit of only needing to deploy a single large model to interact with dozens of consenting clients.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Greatest advantage&lt;/strong&gt;: Perhaps the greatest benefit of multi-environment learning is that we can use this paradigm to train otherwise-standard RL agents to &lt;em&gt;learn to adapt and generalize in context&lt;/em&gt;. In &lt;em&gt;parallel randomized domain learning&lt;/em&gt;, we might train our agent to explore different variations of the same procedurally generated environment simultaneously. In &lt;em&gt;staggered lifelong learning&lt;/em&gt;, we would present the agent with a cirricula of environments which do not all have the same start and end time. Of course, these kinds of techniques would require a &lt;em&gt;large set of environments or even procedural environment generators&lt;/em&gt;. These environments/procedural generators would need to be extremely diverse, so I’m just going to gather them by hand. Soon I hope to have an RL agent that can find more for me.&lt;/p&gt;</content><author><name></name></author><category term="ideas" /><category term="agi" /><summary type="html">Multi-environment learning extends the single environment RL paradigm to multiple environments. It’s like multiagent learning – except your only controlling one agent in multiple environments. In this paradigm, the policy $\pi : o_1, o_2, \dots \rightarrow a_1, a_2, \dots$ takes an observation $o_1, o_2, \dots$ from different environments and produces actions $a_1, a_2, \dots$ for all of them simultaneously on each step. You might have a collection loop like: while True: observations = [env.obs for env in envs] actions = policy(observations) for env, action in zip(envs, actions): env.step(action)</summary></entry></feed>
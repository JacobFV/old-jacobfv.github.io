{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7af7ef-811c-417b-bf26-0ac0ef76fe9b",
   "metadata": {},
   "source": [
    "# Computatrum Project Proposal\n",
    "\n",
    "![](computerenv.png) *The general-purpose computer reasonably covers the anthropocentric problem domain. Performance across many tasks in this open-world domain therefore gives a proxy of development towards `artificial general intelligence'.*\n",
    "\n",
    "The general-purpose computer provides a simple interface to vast distributions of natural and synthetic complexity which reasonably proxy the anthropocentric problem domain. This inherently includes any dataset machine learning practitioners might use, billions hours of recorded audio and video, live social media feeds, uncountable scientific, engineering, business, and historical documents, as well as creative software, integrated development environments, simulators, engineering design tools, e-commerce platforms, business systems, and many more applications. Considered together with the Internet, the general-purpose computer is a ready-made multiagent, language-grounded, lifelong-learning environment-incubator for the development-evolution of progressively more capable, general, and autonomous artificial intelligence.\n",
    "\n",
    "Targeting this open set of tasks is not simple due to their non-stationary distribution. This is further complicated by heterogeneous user interfaces and context-sensitive application of natural world metaphors such as location, navigation, and gesture. Then there is also the issue of estimating task progress, completion, and reward in spite of shifting and overlapping task boundaries. While still keeping complete autonomy in mind as an ultimate objective, these challenges advocate occasionally relaxing the autonomy constraint in exchange for natural language human guidance.\n",
    "\n",
    "Natural language is already ubiquitous across graphical user interfaces. It allows transferring not only objectives but also cognitive models from human to agent thus helping align both the agent’s action and perception. Genuinely expressed natural language (not template statements) communicates deep relational hierarchies and dependencies. Most importantly, natural language is a high-bandwidth channel to rapidly infuse human-oracle information into the policy inference loop online. Rapid feedback accelerates the entire training loop iterating towards increasing capability, generality, and autonomy. Conversely, measuring a computer interaction agent’s sustained alignment with natural language instructions over long trajectories may provide a reasonable proxy of development towards the illusion of artificial general intelligence. (See figure above)\n",
    "\n",
    "![](integratedarchitecture.png) *Overall architecture of a computatrum. (a) Cognitive architecture (this work, colored blue) provides feedback to an online continually learning policy. (b) Goals are encoded are natural language statements at various levels of granularity such as \"type \\$12345.00\", \"enter values from the document in their corresponding fields\", and \"file these electronic faxes\".*\n",
    "\n",
    "This work represents an ambitious step in that direction. **I plan to introduce a heterogeneous multitask, multimodal semi-supervised dataset of recorded computer interactions -- the User Experience (UE) -- and use it to train Computatrum -- a highly advanced AI agent with computer interaction skills rivaling human performance**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f376d001-d5bc-4a4a-9e8f-71d373aa2f2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## The User Experience\n",
    "\n",
    "Computer interaction demands an understanding of diverse modalities: mouse events, keystrokes, language, audio, image, and video. At this scale of complexity, it is not currently feasible to build a massive supervised mouse-keyboard-text-audio-image-video dataset. Even if such a dataset were available, it may be unproductive to build training loops that demand every modality to be present in an example. For example, in many computer applications, the audio modality is ignored. It would be memory and compute efficient to similarly skip audio-related processing in corresponding dataset examples. However, in other applications such as media players, audio is essential and other modalities such as the keyboard and mouse can instead be ignored. Regardless of the modalities involved, this work aims to estimate a similarity measure between their current state and a natural language goal description. To my knowledge, no single dataset combines information from all these diverse modalities. Therefore, in this vain, **I propose developing a heterogeneous multimodal semi/supervised conglomerate dataset of datasets: the User Experience (UE)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347cb271-e37c-4471-8fd5-698c4d866bae",
   "metadata": {},
   "source": [
    "## Computatrum\n",
    "\n",
    "As shown in the first figure, general-purpose computer interaction sits at the nexus of numerous problem domains involving mouse event and keystroke analysis, natural language processing, object detection, action sequence segmentation, audio/video understanding, and control. Drawing on existing contributions, this work combines pretrained models for most modalities separately and only trains a relatively small recurrent-state attention-based joint embedding network. The dot product between the joint embedding produced from computer modalities and the task semantic embedding is used to train a language alignment critic in CLIP-fashion. See below for an anatomical description:\n",
    "\n",
    "![](architecture.png) *The language alignment critic uses a diverse set of modalities to predict a nontrivial vector that aligns with a language description semantic vector. Architecture primarily follows heuristic design.*\n",
    "\n",
    "Neural architecture will likely evolve significantly as this project continues. However as an immutable goal condition, **I propose developing a fully autonomous, open-ended machine learning system the Computatrum -- which interacts using standard peripherals connected to a virtual machine running Ubuntu with Internet access to interact with robots, research sites, and its own software and compute resources. The Computatrum should be capable of self-optimization by examining, modifying, commiting, and deploying copies of its own codebase.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39a95f",
   "metadata": {},
   "source": [
    "## Acceptance test\n",
    "\n",
    "This project aims to build a machine learning system that can be commanded \"Optimize your own code\" and respond with computaer interaction behaviors that improve its productivity on achieving a wide range of goals in various problem domains such as ML engineering, general programming, independant research, and business skills."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
